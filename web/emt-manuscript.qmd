---
title: "EMT manuscript"
format: html
---

```{r setup, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning=FALSE)
library(tidyverse)
library(gt)
library(report)
library(lmerTest)
library(papaja)
library(report)
library(stringr)
library(patchwork)
here::i_am("web/emt-children.qmd")
source(here::here("scripts/prepare-manuscript-data.R"))

relabel_errors <- function(dat){
  dat <- dat %>% 
    mutate(error_type = case_when(
      error_type == "selection" ~ "Item selection",
      error_type == "incorrect_placement" ~ "Placement",
      error_type == "incorrect_object_order" ~ "Object order", 
      TRUE ~ error_type
    ))
  return(dat)
}

df_single <- df_all %>%
  group_by(name, school, age_month, gender) %>%
  slice_head(n = 1) %>%
  ungroup()

source(here::here("scripts/loading-adults.R"), encoding = "UTF-8")
df_emt_adults <- df_emt_adults %>%
  filter(Environment == "House")

df_adults_single <- df_emt_adults %>%
  group_by(ID.x) %>%
  slice_head(n=1)

df_adults_children_combined <- df_emt_adults %>%
  select(error_type, error_value = errors, difficulty,
         relative_correct, ID = bindingid) %>%
  mutate(group = "Adults",
         error_type = case_match(error_type,
          "incorrect_order" ~ "incorrect_object_order", .default = error_type)) %>%
  bind_rows(df_vr %>%
    filter(error_type != "selection") %>%
    select(error_type, difficulty, error_value, relative_correct, ID = name) %>%
    mutate(group = "Children"))
```

```{r, eval = FALSE}
df_vr %>%
  select(difficulty, name, school) %>%
  distinct() %>%
  group_by(difficulty) %>%
  count()
```

```{r demographics age}
df_single %>%
  group_by(gender) %>%
  summarise(n = n(), mean_age = mean(age_month), 
            sd_age = sd(age_month), min_age = min(age_month),
            max_age = max(age_month)) %>%
  gt() %>%
  tab_header(title = "Demographics for the children participants") %>%
  fmt_number(columns = c("mean_age", "sd_age"), decimals = 3) %>%
  tab_spanner(label = "Age in months", columns = c("mean_age", "sd_age", "min_age", "max_age")) %>%
  # relabel variable names mean and sd and min to Mean, SD, Min, Max
  cols_label(mean_age = "Mean",
              sd_age = "SD",
              min_age = "Min",
              max_age = "Max")
```

A total of `r nrow(df_single)` children participated in the study. Age demographics can be seen in Tab XY. Children were recruited from `r n_distinct(df_single$school)` schools. All children completed all trials. 

```{r demographics adults}
df_adults_single %>%
  group_by(Gender) %>%
  summarise(n = n(), mean_age = mean(Age), 
            sd_age = sd(Age), min_age = min(Age),
            max_age = max(Age)) %>%
  gt() %>%
  tab_header(title = "Demographics for the adults") %>%
  fmt_number(columns = c("mean_age", "sd_age"), decimals = 3) %>%
  tab_spanner(label = "Age", columns = c("mean_age", "sd_age", "min_age", "max_age")) %>%
  # relabel variable names mean and sd and min to Mean, SD, Min, Max
  cols_label(mean_age = "Mean",
              sd_age = "SD",
              min_age = "Min",
              max_age = "Max")
```

## Error description

Participant can make one of four distinct errors:

- Item selection error: the participant selected the wrong item when given the option at the beginning of the recollection trial
- Incorrect placement: the participant placed the item in a wrong location
- Object order error: the participant placed the item in a wrong order (different from the order in the instruction)
- Location order error: the participant placed the item (correct or incorrect) in a possible location, but different from the order in the instruction

```{r object location order error corr, message = FALSE, fig.width=10, fig.height=5}
df_location_object_error <- df_vr_unfiltered %>%
  filter(error_type %in% c("incorrect_location_order", "incorrect_object_order")) %>%
  select(-c(relative_error_value, made_error)) %>%
  pivot_wider(names_from = error_type, values_from = error_value)

df_location_object_error %>%
  ggplot(aes(incorrect_location_order, incorrect_object_order)) +
    geom_jitter() +
    geom_smooth(method = "lm") +
    labs(x = "Incorrect location order error", y = "Incorrect object order error", 
        title = "Correlation between incorrect location order error and incorrect object order error") +
    papaja::theme_apa(base_size = 16)

cor_location_object_order_error <- cor.test(df_location_object_error$incorrect_location_order, 
                        df_location_object_error$incorrect_object_order,
                        method="kendall")
```

The object order error and location order errors are in our implementation identical, as it is generally true that when participants places the object in a wrong location, they will also place the object in a wrong order. There are other implementations where the object order error is calculated differently, so the two can be exclusive, but in our case the correlation between object order error and location error is 1 (`r report::report_statistics(cor_location_object_order_error)`), so we left only object order error in the analyses

### Relative accuracy

As there is a difference in the potential number of errors possible at different difficulties (for example, you cannot make four selection mistakes out of three items), we also calculated the **relative accuracy** (1 - errors/maximum posibble errors). So the number 1 in relative accuracy means the best possible performance. This should allow us to consider the performance across different difficulties.

## Average error demographics

```{r fig.width=10, fig.height=15}
#| out-width: 80%
plt_raw_error <- df_adults_children_combined %>%
  # relabel fill selection becomes item selection, incorrect_placement becomes placement error 
  relabel_errors() %>%
  select(difficulty, error_type, error_value, group) %>%
  ggplot(aes(x = as.factor(difficulty), y = error_value, fill = group)) +
    geom_boxplot() +
    guides(fill = "none") +
    papaja::theme_apa(base_size = 18) +
    geom_jitter(width = 0.2, height = 0.05, alpha = 0.5) +
    labs(x = "", y = "Absolute number of errors") +
    facet_wrap(~error_type)

plt_relative_correct <- df_adults_children_combined %>%
  relabel_errors() %>%
  select(difficulty, relative_correct, error_type, group) %>%
  ggplot(aes(x = as.factor(difficulty), y = relative_correct, fill = group)) + 
    geom_jitter(width = 0.2, height = 0.05, alpha = 0.5) +
    labs(x = "Trial difficulty", y = "Relative accuracy (1 is perfect performance)") +
    geom_boxplot() +
    papaja::theme_apa(base_size = 18) +
    theme(legend.position = "bottom") +
    facet_wrap(~error_type)

plt_raw_error / plt_relative_correct +
  plot_annotation(
    title = "Error descriptives",
    caption = '',
    theme = theme(plot.title = element_text(size = 26, hjust = 0.5))
  )
```

## Increasing number of errors with increasing difficulty

```{r error descriptive table}
df_adults_children_combined %>%
  relabel_errors() %>%
  group_by(error_type, difficulty, group) %>%
  summarise(absolute_errors = str_glue("M = {round(mean(error_value),3)} ({round(sd   (error_value),3)})"),
            relative_accuracy = str_glue("M = {round(mean(relative_correct),3)} ({round(sd(relative_correct),3)})")) %>%
      pivot_longer(cols = c(absolute_errors, relative_accuracy), values_to = "value") %>%
    pivot_wider(names_from = difficulty, values_from = value) %>%
    group_by(name, group) %>%
  gt() %>%
  tab_header(title = "Error descriptives", 
             subtitle = "Mean and standard deviation of absolute errors and relative accuracy across different difficulties")
```

```{r}
df_vr %>%
  group_by(error_type) %>%
  group_modify(~report_table(aov(error_value ~ difficulty, data = .x))) %>%
  gt() %>%
  tab_header(title = "ANOVA for error types and difficulty") %>%
  fmt_number(columns = where(is.numeric), decimals = 3)

aov_order_difficulty <- aov(error_value ~ as.factor(difficulty), data = filter(df_vr, error_type == "incorrect_object_order"))
aov_placement_difficulty <- aov(error_value ~ as.factor(difficulty), data = filter(df_vr, error_type == "incorrect_placement"))
aov_selection_difficulty <- aov(error_value ~ as.factor(difficulty), data = filter(df_vr, error_type == "selection"))
```

We can see that the number of errors increases with increasing difficulty for both object order error (`r report_statistics(aov_order_difficulty)`) and placement error (`r report_statistics(aov_placement_difficulty)`), but not in the selection error (`r report_statistics(aov_selection_difficulty)`).

```{r}
TukeyHSD(aov_order_difficulty)[[1]] %>%
  as.data.frame() %>%
  rownames_to_column(var = "difficulty comparison") %>%
  gt() %>%
    tab_header(title = "Tukey HSD for object order error") %>%
    fmt_number(columns = where(is.numeric), decimals = 3)

TukeyHSD(aov_placement_difficulty)[[1]] %>%
  as.data.frame() %>%
  rownames_to_column(var = "difficulty comparison") %>%
  gt() %>%
    tab_header(title = "Tukey HSD for placement errors") %>%
    fmt_number(columns = where(is.numeric), decimals = 3)
```

::: {.callout-warning}
Just to remind, if one location is incorrect, then more locations will be incorrect after that, as the participant will not be able to place the objects correctly. This will overestimate the number of errors in later trials, as the errors are not independent and it is almost impossible to do "just one error" in the order of objects. Selection and placement are independent from one item to another.
:::

## Effect of age on performance

```{r age and performance, eval = FALSE}
df_vr %>%
  group_by(name, error_type) %>%
  relabel_errors() %>%
  slice_head(n = 1) %>%
  ggplot(aes(age_months, all_trials_avg_relative_correct, color = gender)) +
  geom_point() +
  facet_grid(cols = vars(error_type), scales = "free_y") +
  geom_smooth(method = "lm") +
  labs(x = "Age (months)", y = "Average relative accuracy value (1 - error / difficulty)", 
       title = "Relative accuracy in averaged for all three trials") +
  papaja::theme_apa(base_size = 18) +
  theme(legend.position = "bottom")
```

```{r, results = "asis"}
lmer_rel_age_diff <- lmerTest::lmer(relative_correct ~ age_months*gender + (1|name), data = df_vr)
report(lmer_rel_age_diff)
```

There is no significant effect of age on the performance in the VR task. No effect of gender or the interaction between the two either. 

## Validation with standard tests

Maximum theoretical points is 40 for the story repetition and 34 for the sentence repetition. Higher score is better. 

```{r story and sentence descriptives}
df_all %>%
  group_by(name) %>%
  slice_head(n = 1) %>%
  ungroup() %>%
  select(name, NR, SR) %>%
  filter(!is.na(NR)) %>%
  summarise(mean_NR = mean(NR), sd_NR = sd(NR), min_NR = min(NR), max_NR = max(NR),
            mean_SR = mean(SR), sd_SR = sd(SR), min_SR = min(SR), max_SR = max(SR)) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") %>%
  separate(variable, into = c("var", "test"), sep = "_") %>%
  pivot_wider(names_from = var, values_from = value) %>%
  mutate(test = case_when(
    test == "NR" ~ "Story repetition",
    test == "SR" ~ "Sentence repetition",
    TRUE ~ test
  )) %>%
  gt() %>%
  tab_header(title = "Descriptives of standard tests") %>%
  fmt_number(columns = c(mean, sd), decimals = 3)
```

```{r relationship between sentence, fig.width=10, fig.height=12 }
plt_nr_accuracy <- df_all %>%
  group_by(name, error_type) %>%
  relabel_errors() %>%
  slice_head(n = 1) %>%
  ggplot(aes(all_trials_avg_relative_correct, NR)) +
  geom_point() +
    geom_smooth(method = "lm", color = "brown") +
    facet_wrap(~error_type, scales = "free") +
    labs(x = "Relative accuracy (averaged across all trials)", 
         y = "Story repetition score" , 
         title = "Relationship between relative accuracy and story repetition score for all trials") +
  papaja::theme_apa(base_size = 16)

plt_sr_accuracy <- df_all %>%
  group_by(name, error_type) %>%
  relabel_errors() %>%
  slice_head(n = 1) %>%
  ggplot(aes(all_trials_avg_relative_correct, SR)) +
    geom_point() +
    geom_smooth(method = "lm", color = "violet") +
    facet_wrap(~error_type, scales = "free") +
    labs(x = "Relative accuracy (averaged across all trials)", 
         y = "Sentence repetition score" , 
         title = "Relationship between relative accuracy and sentence repetition score for all trials") +
  papaja::theme_apa(base_size = 16)

plt_nr_accuracy / plt_sr_accuracy 
```

```{r story repetition score}
df_cor_NR <- df_all %>%
  group_by(error_type) %>%
  group_modify(~broom::tidy(cor.test(.$NR, .$relative_correct, method = "spearman"))) %>%
  select(estimate, statistic, p.value) %>%
  mutate(p.value = papaja::apa_p(p.adjust(p.value)),
        value = "Story repetition") %>%
  ungroup() 

df_cor_SR <- df_all %>%
  group_by(error_type) %>%
  group_modify(~broom::tidy(cor.test(.$SR, .$relative_correct, method = "spearman"))) %>%
  select(estimate, statistic, p.value) %>%
  mutate(p.value = papaja::apa_p(p.adjust(p.value)), 
        value = "Sentence repetition") %>%
  ungroup()

df_cor_NR %>%
  bind_rows(df_cor_SR) %>%
  relabel_errors() %>%
  select(value, everything()) %>%
  group_by(value) %>%
  gt() %>%
    tab_header(title = "Correlation between relative accuracy and story/sentence repetition score",
      subtitle = "Spearman correlation") %>%
    fmt_number(columns = where(is.numeric), decimals = 2) %>%
    # add footnote corrected for mutliple comparisons to the header
    tab_footnote(
      footnote = "Corrected for multiple comparisons using FDR method within each category (story or sentence repetitions)",
      locations = cells_column_labels(vars(p.value))
    )
```

## Adults vs. children

```{r comparison adults children descriptives}
df_adults_children_combined %>%
  relabel_errors() %>%
  group_by(group, error_type) %>%
  summarise(report_val = str_glue("{round(mean(error_value), 3)} ({round(sd(error_value), 3)})")) %>%
  pivot_wider(names_from = group, values_from = report_val) %>%
  gt() %>%
    tab_header(title = "Descriptives of error values in adults and children in different error types for 5 item difficulty",
              subtitle = "Mean (SD)")
```

```{r comparison adults children test}
df_adults_children_combined %>%
  relabel_errors() %>%
  group_by(error_type) %>%
  group_modify(~report_table(t.test(error_value ~ group, data = .))) %>%
  select(-c(Parameter, Group, starts_with("CI"), Method, Alternative, starts_with("d_CI"))) %>%
  ungroup() %>%
  gt() %>%
    tab_header(title = "Comparison of error values in adults and children in different error types for 5 item difficulty",
              subtitle = "Independent samples t-test") %>%
    fmt_number(columns = where(is.numeric), decimals = 3)
```

### Aduts RBANS

```{r}
df_emt_adults %>%
  # filter(Environment == "House") %>%
  pivot_longer(c(RBANS.A.1, RBANS.A.2), 
              names_to = "RBANS", 
              values_to = "RBANS_value") %>%
  mutate(avg_relative_correct = mean(relative_correct, na.rm = TRUE), .by = ID.x) %>%
  select(avg_relative_correct, Environment, error_type, RBANS, RBANS_value) %>%
  relabel_errors() %>%
  group_by(Environment, error_type, RBANS) %>%
  group_modify(~broom::tidy(cor.test(.$RBANS_value, .$avg_relative_correct, method = "spearman"))) %>%
  summarise(result = str_glue("r = {round(estimate, 3)} (p = {apa_p(p.value)})")) %>%
  pivot_wider(names_from = RBANS, values_from = result) %>%
  ungroup() %>%
  gt() %>%
  tab_header(title = "Correlation between RBANS and EMT for house environment",
             subtitle = "Spearman's rho, not corrected for multiple comparisons. Average house performance across all trials")
```