---
title: "VR test reports"
format: html
---

```{r setup, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
library(tidyverse)
library(gt)
here::i_am("web/vr-emt.qmd")
```

```{r loading, message=FALSE, warning=FALSE}
source(here::here("scripts/loading.R"))
```

```{r}
knitr::kable(head(df_vr))
```

## Descriptives
```{r}
df_vr %>%
  select(name, age_months, gender) %>%
  distinct() %>%
  ggplot(aes(age_months, fill = gender)) +
    geom_histogram(binwidth = 3) + 
    labs(x = "Age (months)", y = "Count", 
    title = "Age distribution of participants")
```

## Finishing

```{r completed}
df_vr %>%
  distinct(name, difficulty, age_months) %>%
  count(name, age_months) %>%
  count(n)
```

All children have finished all conditions.

### Errors 

::: {.callout-tip}

CO = correct objects/správné předměty resp. Jejich Chyby (už přepočítáno)

OPE = object position errors/chyby v pozici

OOE = object order errors/chyby v pořadí předmětu

LOE = location order errors/chyby v pořadí pozice
:::

These errors were renamed to a bit clearer naming schemes to prevent OOE, OPE etc.

::: {.callout-tip}
The errors come in four different types:

- selection error: the participant selected the wrong item

- incorrect_placement: the participant placed the item at a wrong position

- incorrect_object_order: the participant placed the item at a wrong order

- incorrect_location_order: the participant placed the item at a location in a wrong order?
:::

```{r error descriptives, echo = FALSE, message = FALSE}
df_error_desc <- df_vr %>%
  group_by(difficulty, error_type) %>%
  summarise(mean_error = mean(error_value), 
            sd_error = sd(error_value),
            sd_error_mean = sd(error_value) / sqrt(n()),
            min = min(error_value),
            max = max(error_value),
            median = median(error_value))

df_rel_error_desc <- df_vr %>%
  group_by(difficulty, error_type) %>%
  summarise(mean_error = mean(relative_error_value), 
            sd_error = sd(relative_error_value),
            sd_error_mean = sd(relative_error_value) / sqrt(n()),
            min = min(relative_error_value),
            max = max(relative_error_value),
            median = median(relative_error_value))

df_error_desc %>%
  select(-sd_error_mean) %>%
  gt() %>%
  tab_header(title = "Descriptives of error values in different difficulties and error types") %>%
  fmt_number(columns = where(is.numeric), decimals = 2)
```

```{r error descriptives plot}
df_error_desc %>%
  ggplot(aes(difficulty, mean_error, fill = error_type)) +
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = mean_error - sd_error_mean, ymax = mean_error + sd_error_mean), 
                position = position_dodge(width = 0.9), width = 0.25) +
  labs(x = "Difficulty", y = "Mean error value", 
    title = "Mean error values in different difficulties and error types") 
```
### Relative error
As there is a difference in the potential number of errors possible at different difficulties, we also calculated the relative error value (error / difficulty). So the number 1 means the maximum number of errors possible at that difficulty.

```{r error relative descriptives plot}
df_rel_error_desc %>%
  ggplot(aes(error_type, mean_error, fill = factor(difficulty))) +
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = mean_error - sd_error_mean, ymax = mean_error + sd_error_mean), 
                position = position_dodge(width = 0.9), width = 0.25) +
  labs(x = "Difficulty", y = "Mean relative error value",
       title = "Mean relative error values in different difficulties and error types") +
  #make the x labels 45 degrees
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

So it looks like increasing number of items also increases the general error. So children are probably not simply remembering the first three locations or objects, but just not remembering anything much at all. Average relative error for all types of errors is above 40 percent, with the exception of selection.


::: {.callout-warning}
The other very probably explanation is the dependency of the errors. If one location is incorrect, then more locations will be incorrect after that, as the participant will not be able to place the objects correctly. This will overestimate the number of errors, as the errors are not independent.

:::

## VR test results in different ages

```{r}
ggplot(df_vr, aes(age_months, relative_error_value)) +
  geom_point() +
  facet_grid(rows = vars(difficulty), cols = vars(error_type), scales = "free_y") +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Age (months)", y = "Relative error value (error / difficulty)", 
        title = "Relative error in individual error types and difficulties")
```

Overall there seems to be a trend of older children to make more mistakes, especially in the 4 items difficutly.

```{r logistic regression}
df_vr %>%
  mutate(made_error = as.numeric(error_value > 0)) %>%
  ggplot(aes(age_months, made_error)) +
  geom_point() +
  facet_grid(rows = vars(difficulty), cols = vars(error_type), scales = "free_y") +
  stat_smooth(method="glm", color="green", se=FALSE, 
    method.args = list(family=binomial)) + 
    labs(x = "Age (months)", y = "Has the participant made any error", 
            title = "VR logistic regression of made error (error > 0) for each difficulty and error type")
``` 

Similar trend is even for the logistic regression modelling the likelihood of making any error. There seems to be an upward trend for older children to making errors more likely.

:::{.callout-note}
There are a few possible explanations

- the data are missing the time component, so we do not kno how long it actually took the children to answer or how much they moved in the environemnt

- It is possible, that the researcher might have been more supportive with the younger children

- Finally, it is possible that thje researcher might ahve solved the task for the young children (as is suggested in the thesis, that the reearcher kept helping children unable to control the environment on their own), but this information is missing. 
:::

## Correlation with other metrics

### Story repetition

Maximum points is 40 for the story repetition and 34 for the sentence repetition. Higher score is better.

```{r story repetition score plot}
df_all %>%
  ggplot(aes(error_value, NR)) +
  geom_point() +
    geom_smooth(method = "lm") +
facet_grid(rows = vars(difficulty), cols = vars(error_type), scales = "free") + 
  labs(x = "Error value", y = "Story repetition score", 
            title = "Correlation between error value and story repetition score. Split by difficulty")

df_all %>%
  ggplot(aes(error_value, NR)) +
  geom_point() +
    geom_smooth(method = "lm") +
    facet_wrap(~error_type, scales = "free") +
    labs(x = "Error value", y = "Story repetition score", 
            title = "Correlation between error value and story repetition score")
```

```{r story repetition score}
df_all %>%
  group_by(error_type) %>%
  group_modify(~broom::tidy(cor.test(.$NR, .$error_value, method = "spearman"))) %>%
  select(estimate, statistic, p.value) %>%
  mutate(p.value = papaja::apa_p(p.adjust(p.value))) %>%
  ungroup() %>%
  gt() %>%
    tab_header(title = "Correlation between error value and story repetition score",
      subtitle = "Spearman correlation between error value and story repetition score for each error type") %>%
    fmt_number(columns = where(is.numeric), decimals = 2) %>%
    # add footnote corrected for mutliple comparisons to the header
    tab_footnote(
      footnote = "Corrected for multiple comparisons using FDR method",
      locations = cells_column_labels(vars(p.value))
    )
```

### Sentence repetition

```{r sentence repetition score plot}
df_all %>%
  ggplot(aes(error_value, SR)) +
  geom_point() +
    geom_smooth(method = "lm") +
facet_grid(rows = vars(difficulty), cols = vars(error_type), scales = "free") + 
  labs(x = "Error value", y = "Stentence repetition score", 
            title = "Correlation between error value and sentence repetition score. Split by difficulty")

df_all %>%
  ggplot(aes(error_value, SR)) +
  geom_point() +
    geom_smooth(method = "lm") +
    facet_wrap(~error_type, scales = "free") +
    labs(x = "Error value", y = "Sentence repetition score", 
            title = "Correlation between error value and sentence repetition score for all difficulties")
```

```{r sentence repetition score}
df_all %>%
  group_by(error_type) %>%
  group_modify(~broom::tidy(cor.test(.$SR, .$error_value, method = "spearman"))) %>%
  select(estimate, statistic, p.value) %>%
  mutate(p.value = papaja::apa_p(p.adjust(p.value))) %>%
  ungroup() %>%
  gt() %>%
    tab_header(title = "Correlation between error value and sentence repetition score",
      subtitle = "Spearman correlation between error value and stencence repetition score for each error type") %>%
    fmt_number(columns = where(is.numeric), decimals = 2) %>%
    # add footnote corrected for mutliple comparisons to the header
    tab_footnote(
      footnote = "Corrected for multiple comparisons using FDR method",
      locations = cells_column_labels(c(p.value))
    )
```

## Hiding task

The kendall rank correlation was used due to the very low number of errors in both cases and ordinal nature fo the data. Visualisation is difficult due to the nature of the dataset. 

```{r hiding task kendall}
df_all %>%  
  select(name, school, error_value, error_type, starts_with("plush_"), -plush_what, -plush_what_actor) %>%
  pivot_longer(starts_with("plush_"), names_to = "hiding_task", values_to = "hiding_task_value") %>%
  group_by(error_type, hiding_task) %>%
  group_modify(~broom::tidy(cor.test(.$hiding_task_value, .$error_value, method = "kendall"))) %>%
  select(estimate, statistic, p.value) %>%
  mutate(p.value = papaja::apa_p(p.adjust(p.value))) %>%
  ungroup() %>%
  gt() %>% 
    tab_header(title = "Kendall rank correlation between error value from the VR and hiding task score",
      subtitle = "Kendall correlation used due to many pairwise comparisons and ordinal data") %>%
    fmt_number(columns = where(is.numeric), decimals = 2) %>%
    # add footnote corrected for mutliple comparisons to the header
    tab_footnote(
      footnote = "Corrected for multiple comparisons using FDR method",
      locations = cells_column_labels(c(p.value))
    )

```
